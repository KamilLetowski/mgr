\chapter{Ogólny problem}
Badany problem jest w informatyce nazywany problemem komiwoja¿era. W tym rozdziale zostanie on omówiony oraz metody optymalizacji.

\section{Problem komiwoja¿era} 
Problem komiwoja¿era (ang. travelling salesman problem - TSP) nale¿y do rodziny problemów NP-trudnych. Znalezienie najlepszego rozwi¹zania jest trudne i fascynuje naukowców od wielu lat. Niektórzy poddaj¹ pod w¹tpliwoœæ znalezienie efektywnego rozwi¹zania, czyli takiego którego czas dzia³ania jest maksymalnie wielomianowy. Aktualnie istnieje wiele rozwi¹zañ tego problemu, a proponowane podejœcia s¹ bardzo interesuj¹ce. Niektóre z nich bazuj¹ na lokalnych przeszukiwaniach grafu, a inne opieraj¹ siê na przyk³adach które wystêpuj¹ w przyrodzie.

Podobnym problemem do TSP jest problem konika szachowego. Problem ten równie¿ nale¿y do rodziny problemów NP-zupe³nym. Ju¿ w XVIII wieku badania nad tym problemem rozpocz¹³ Euler. Rozwi¹zanie tego problemu polega na znalezieniu œcie¿ki jak¹ ma przebyæ konik szachowy, tak aby odwiedziæ ka¿de pole na szachownicy tylko i wy³¹cznie raz. Skoczek porusza siê po planszy zgodnie z okreœlonym ruchem, a plansza szachowa mo¿e mieæ ró¿ny rozmiar. Konik porusza siê a¿ do momentu odwiedzenia wszystkich pól lub do momentu w którym nie ma mo¿liwoœci odwiedzenia kolejnego pola.

Optymalizacja tras od zawsze jest obecna w historii ludzkoœci. Nawet takie trywialne problemy jak podró¿ pomiêdzy 3 miejscowoœciami mo¿e zostaæ sklasyfikowany jako problem komiwoja¿era. Chocia¿ dok³adne wskazanie na Ÿród³o problemu TSP nie jest znane, to ju¿ w 1832 roku w przewodniku dla podró¿uj¹cych po Niemczech i Szwajcarii zosta³a zawarta informacja o optymalizacji trasy przejazdu. Nie ma tam zawartych ¿adnych teorii matematycznych w zwi¹zku z czym nie mo¿na uznaæ tego dzie³a za pocz¹tek rozwa¿añ nad problemem komiwoja¿era.\cite{kl_poczatek_rozwazan}

W XIX wieku William Hamilton stworzy³ fundamenty pod definicjê TSP. W rozwi¹zaniu problemu komiwoja¿era nale¿y znaleŸæ cykl w grafie. W sk³ad takiego cyklu musi zostaæ zawarty ka¿dy z wierzcho³ków. Ka¿dy z wierzcho³ków mo¿e znajdowaæ siê w rozwi¹zaniu dok³adnie tylko raz. Cykl który spe³nia wymieniony warunek jest cyklem Hamiltona. Jeœli w grafie mo¿na wyró¿niæ cykl z opisanymi powy¿ej warunkami, to graf jest grafem Hamiltonowskim. 

Na \ref{kl_graf_nie_hamiltona} zosta³ przedstawiony graf bez cyklu Hamiltona. W grafie tym nie mo¿na znaleŸæ takiego po³¹czenia które zawiera wszystkie wierzcho³ki przechodz¹c przez ka¿dy z nich dok³adnie raz. Istnieje mo¿liwoœæ przejœcia przez wszystkie wierzcho³ki jedynie po powtórnym odwiedzeniu przynajmniej jednego wierzcho³ka.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_graf_nie_hamiltona.png}
	\caption{Graf bez cyklu Hamiltona.}
	\label{kl_graf_nie_hamiltona}
\end{figure}

Graf z \ref{kl_graf_hamiltona} posiada po³¹czenie krawêdzi dziêki któremu mo¿na przejœæ po wszystkich wierzcho³kach dok³adnie raz. Takie przejœcie jest w³aœnie cyklem Hamiltona w zwi¹zku z czym graf jest Hamiltonowski. Wyruszaj¹c przyk³adowo z punktu F mo¿emy przejœæ kolejno do E - G - D - B - A - C. W ten sposób odwiedzimy wszystkie wierzcho³ki tylko raz. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_graf_hamiltona.png}
	\caption{Graf z cyklem Hamiltona.}
	\label{kl_graf_hamiltona}
\end{figure}

W latach 30 XX wieku Merrill Meeks Flood rozpocz¹³ rozwa¿ania nad optymalizacj¹ przejazdu autobusów szkolnych. Dzia³alnoœæ t¹ mo¿emy uznaæ za pocz¹tek pracy nad problemem TSP. Wraz z up³ywem czasu zainteresowanie problemem optymalizacyjnym narasta³o, a co za tym idzie powstawa³y nowe pomys³y na algorytmy. Jednak ¿aden z pomys³ów nie jest w stanie zaproponowaæ dok³adnego rozwi¹zania które jest w stanie przedstawiæ rezultat w czasie wyra¿onym za pomoc¹ wielomianu.

\section{Metody optymalizacji} 
	
Jednym z proponowanych rozwi¹zañ jest algorytm Helda Karpa który jest oparty na programowaniu dynamicznym. Z³o¿onoœæ pamiêciowa tego algorytmy wynosi $\theta$(\(2n^n\))
, a czasowa $\theta$(\(n^2*2^n\)). W algorytmie tym na ka¿dym kroku wyznaczamy punkt który powinien byæ przedostatni na trasie. Aby wyznaczyæ poprzednika nale¿y skorzystaæ ze wzoru w którym poszukiwana jest najmniejsza wartoœæ pomiêdzy punktami.

Innym przyk³adem , który mo¿na wykorzystaæ do rozwi¹zania problemu komiwoja¿era jest algorytm najbli¿szego s¹siada. Rozwi¹zanie to wykorzystuje strategiê zach³ann¹. W algorytmie szukamy aktualnie najlepszego ruchu. W tym celu przeszukiwani s¹ jedynie s¹siedzi którzy s¹ najbli¿ej aktualnego punktu. Z³o¿onoœæ takiego algorytmu jest szacowana na $\theta$(\(n^2\)).

Oprócz standardowych przeszukiwañ zbiorów na przestrzeni lat pojawi³y siê propozycje które wprowadzaj¹ elementy losowoœci. Przyk³adem takiego rozwi¹zania mogê byæ algorytm genetyczny oraz algorytm mrówkowy. Nale¿¹ one do grup algorytmów heurystycznych, czyli do takich, które nie daj¹ gwarancji znalezienia dok³adnego rozwi¹zania.

W pracy zostan¹ zbadane rozwi¹zania problemu za pomoc¹ algorytmu genetycznego, mrówkowego oraz zach³annego. W pozosta³ych podrozdzia³ach zostan¹ opisane ich klasyczne wersje.

\subsection{Algorytm genetyczny - Pawe³}
Algorytm genetyczny (ang.  \textit{GA - Genetic Algorithm}) polega na symulacji procesów genetycznych zachodz¹cych w populacjach osobników, stosuje siê je g³ównie przy zadaniach optymalizacyjnych. W przyrodzie wiêkszoœæ gatunków od wieków, w tym przede wszystkim i cz³owiek, w kolejnych swoich pokoleniach siê rozwinê³o i dostosowa³o do otaczaj¹cych warunków na œwiecie. Gdy jakiœ osobnik urodzi siê z cech¹, która jest przydatna w przetrwaniu, przeka¿ê tê cechê kolejnym pokoleniom. Najs³absze osobniki w populacji maj¹ zarówno mniejsze szanse na przetrwanie oraz rozmno¿enie, czyli przekazanie swoich cech potomkom. W przyrodzie zazwyczaj silniejsi wygrywaj¹. W latach 50 XX wieku zaczêto symulowaæ te procesy w informatyce. W latach 60 John Henry Holland zastosowa³ algorytm genetyczny przy pracach nad systemami adaptacyjnymi, a 1975  wyda³ ksi¹¿kê \textit{Adaptation in Natural and Artificial Systems}, w której to opisa³.\cite{genetic_1}. Algorytm genetyczny poszukuje najlepsze rozwi¹zania, wœród populacji potencjalnych rozwi¹zañ. Jest to g³ówna cecha, która odró¿nia go od tradycyjnych metod optymalizacji. Ka¿de rozwi¹zanie ulega ocenie na podstawie jego dopasowania do problemu - funkcja przystosowania. Algorytm na populacji symuluje zjawiska ewolucyjne, krzy¿uj¹c i mutuj¹c rozwi¹zania, stosuj¹c probabilistyczne regu³y wyboru. W ka¿dym takim nowym pokoleniu najs³absi s¹ usuwani, wiêc w kolejnych etapach populacja sk³ada siê z coraz to lepszych rozwi¹zañ \cite{genetic_9}. Kolejne pokolenia s¹ generowane, a¿ zostanie spe³niony warunek zakoñczenia. Mo¿e to byæ z góry ustalony czas trwania, iloœæ kolejnych pokoleñ lub brak poprawy wœród nowych rozwi¹zañ.

Algorytmy genetyczne i jego odmiany zrewolucjonizowa³y systemy informatyczne. Nie s¹ one algorytmami, które wyliczaj¹ dok³adne wyniki, ale przy odpowiedniej implementacji i ustaleniu parametrów wejœciowych, pozwalaj¹ osi¹gn¹æ dobre rezultaty. Bardzo wa¿ny jest czas znalezienia takiego rozwi¹zania. Jeœli rozwi¹zanie idealne obliczane jest przez algorytm tradycyjny w ci¹gu 24 godziny, a algorytm genetyczny w trakcie kilku minut znajdzie rozwi¹zanie bêd¹ce w s¹siedztwie, swoj¹ efektywnoœci¹ wygra ten drugi.  U¿ytkownik nie bêdzie chcia³ czekaæ ca³ej doby na wynik swojego zapytania. Oczywiœcie, algorytmy genetyczne te¿ mog¹ znaleŸæ najlepsze rozwi¹zanie. Kwesti¹ ograniczenia jest zawsze czas.

Medycyna jest jedn¹ z wa¿niejszych dziedzin, gdzie wykorzystuje siê algorytmy genetyczne. Zbiory danych i przestrzeñ przeszukiwañ jest ogromna i z³o¿ona. Zazwyczaj w oparciu o te informacjê, lekarz musi podj¹æ decyzjê, czy np. nowotwór jest z³oœliwy, czy ma ³agodny przebieg. Algorytm genetyczny pozwala wspomóc lekarza przy podejmowania takich decyzji, przetwarzaj¹c i analizuj¹c te ogromne zbiory. \cite{genetic_2}. Kolejn¹ ga³êzi¹ gospodarki, w których zastosowanie znajduje algorytm genetyczny, jest przemys³ spo¿ywczy, a konkretnie optymalizacja linii produkcyjnych. Za ich pomoc¹ algorytmu genetycznego wyznacza siê parametry takie jak temperatura, ciœnieniu lub zapotrzebowanie mocy. Dziêki temu wszystkie procesy technologiczne zachodz¹ce w maszynach i urz¹dzeniach s¹ wydajne i zoptymalizowane\cite{genetic_4}. Algorytmy genetyczne czêsto stosuje siê jako  wskazanie punktów pocz¹tkowych w innych metodach optymalizacyjnych. Poza podanymi przyk³adami, znajduj¹ one zastosowanie praktycznie wszêdzie: ekonomia, gie³da, przemys³ lotniczy, kombinatoryka, sieci komputerowe, zarz¹dzanie ³añcuchem dostaw, a tak¿e ustalanie czasu reklamy w telewizji \cite{genetic_5}.



\subsection{Algorytm mrówkowy}

Obserwacje nad zachowaniami w przyrodzie wielokrotnie mia³y wp³yw na rozwój nowych rozwi¹zañ. Tak jak w przypadku algorytmu genetycznego, tak i w przypadku algorytmu mrówkowego pomys³ zosta³ zaczerpniêty z przyrody. Dok³adne dzia³anie algorytmu mrówkowego wzoruje siê na zachowaniu kolonii mrówek. Dziêki pracy zespo³owej, owady te s¹ w stanie wypracowaæ optymaln¹ œcie¿kê miêdzy siedliskiem a znalezionym pokarmem.

Dla niejednego gatunku problematyczne mog³oby byæ odtworzenie przebytej œcie¿ki. Na pocz¹tku nale¿a³oby zadaæ sobie pytanie w jaki sposób te niewielkich rozmiarów owady s¹ w stanie znacz¹co u³atwiæ sobie przetrwanie? Istotn¹ rolê odgrywa tutaj wspomniana ju¿ praca zespo³owa. To dziêki niej mrówki s¹ w stanie optymalizowaæ trasê. Innym wa¿nym czynnikiem determinuj¹cym poprawê œcie¿ki jest zapach jaki zostawiaj¹ mrówki. 

Zapach nie jest niczym innym jak feromonem wytwarzanym przez mrówki. Dziêki pozostawionemu zapachowi mrówki identyfikuj¹ w jaki sposób poruszali siê ich poprzednicy w zwi¹zku z czym odtworzenie trasy nie stanowi³o ju¿ powa¿nego problemu. Przy kolejnych iteracjach, kolonia próbuje optymalizowaæ aktualn¹ trasê. W tym celu równie¿ wykorzystuje zapach pozostawiony w poprzednich przejœciach. Œcie¿ka jest losowo zmieniana w celu optymalizacji. Jeœli modyfikacja przynios³a oczekiwany efekt, to trasa zostaje zmieniona.

Algorytm mrówkowy znajduje swoje zastosowanie w rozwi¹zywaniu innych problemów. Problem plecakowy jest jednym z takich przyk³adów. Pojawia siê on najczêœciej przy optymalnym zarz¹dzaniu zasobami. Mamy dany zbiór jakichœ przedmiotów z czego ka¿dy z nich posiada okreœlony ciê¿ar i wartoœæ. Do plecaka musimy za³adowaæ przedmioty o jak najwiêkszej wartoœci. Naszym ograniczeniem jest jednak ³¹czny ciê¿ar przedmiotów które mo¿emy udŸwign¹æ. 

Algorytm mrówkowy wygl¹da bardzo podobnie w tym przypadku. Na pocz¹tku jest $N$ agentów - mrówek. Ka¿dy agent iteracyjnie poszukuje jak najlepszego rozwi¹zania. Po ka¿dej iteracji mo¿na wyró¿niæ trzy typy rozwi¹zañ: rozwi¹zanie poœrednie, rozwi¹zanie czêœciowe lub stan. Agenci w celu znalezienia rozwi¹zania wykorzystuj¹ swoje naturalne umiejêtnoœci czyli zostawiaj¹ na wszystkich obiektach w plecaku feromony. Dziêki lotnoœci feromonów mrówki s¹ w stanie identyfikowaæ bardziej zadowalaj¹ce przedmioty.

Krzysztof Schiff w artykule Ant colony optimization algorithm for the 0-1 knapsack\cite{kl_alg_plecakowy} przedstawi³ rozwi¹zanie problemu plecakowego. Do wyboru najlepszego rozwi¹zania wykorzystane zosta³y trzy metody. Zgodnie z przyjêt¹ konwencj¹ przez autora artyku³u metody maj¹ odpowiednie nazwy: AKA1, AKA2 oraz AKA3. Za wybór najlepszego rozwi¹zania odpowiadaj¹ wzory: 
	\[
	    AKA1 = \frac{z}{\frac{w}{V}}
	\]
	\[
	    AKA2 = \frac{z}{w^2}
	\]
	\[
	    AKA3 = \frac{z}{\frac{w}{C}}
	\]
gdzie:\\
-- z jest zyskiem wybranego obiektu;\\
-- w jest wag¹ wybranego obiektu;\\
-- V jest aktualn¹ ³adownoœci¹ plecaka;\\
-- z jest zyskiem wybranego obiektu;\\
-- C jest ca³kowit¹ wag¹ plecaka.\\

Problem komiwoja¿era i problem plecakowy s¹ problemami kombinatorycznymi. Ich rozwi¹zanie polega na poszukiwaniu optymalnej œcie¿ki na grafie pe³nym. Inna odmian¹ problemu jest kolorowania grafu. W tej wariacji problem jest od razu zadany na grafie. Dla wszystkich wierzcho³ków w grafie nale¿y dobraæ takie kolory, aby ¿adne dwa s¹siednie wierzcho³ki nie mia³y tego samego koloru \cite{kl_inne_alg_mrowkowe}. 

Mrówki nie dzia³aj¹ bezpoœrednio na grafie pocz¹tkowym poniewa¿ graf ten nie musi byæ grafem pe³nym. Nale¿y stworzyæ dla mrówek alternatywê podobn¹ do orygina³u z zachowaniem takiego samego zbioru wierzcho³ków ale z pe³nymi krawêdziami. Nastêpnie nale¿y dobraæ numeryczne wartoœci odpowiadaj¹ce konkretnym kolorom. Jeœli mrówka odwiedzi dany wierzcho³ek, to zostaje on pokolorowany na najni¿szy kolor który nie zosta³ dotychczas u¿yty do kolorowania któregoœ z s¹siadów.

Tak jak w przypadku poprzednich algorytmów wykorzystywane s¹ zapachy pozostawiane przez mrówki. Iloœæ u¿ytych unikalnych kolorów by³aby odwrotnie proporcjonalna do iloœci feromonów. W efekcie czego heurystyka by³aby odwrotnie proporcjonalna do wykorzystanych kolorów po kolejnych iteracjach. Wynikiem tych operacji bêdzie rozwi¹zanie w którym, w grafie oryginalnym ka¿dy wierzcho³ek bêdzie odwiedzany tylko raz.

Ostatni z przyk³adów wykorzystania algorytmu mrówkowego jest harmonogram produkcji. W porównaniu do poprzednich metod w tym algorytmie zachodzi pewna modyfikacja. G³ównym problemem w harmonogramie produkcji jest znalezienie takiej kolejnoœci przetwarzanych zadañ, aby jak najszybciej je przetworzyæ. Aby lepiej zobrazowaæ t¹ sytuacjê nale¿y sobie wyobraziæ fabrykê w której znajduj¹ siê linie produkcyjne. Na linii s¹ przetwarzane zadania w odpowiedniej kolejnoœci oraz ka¿de z zadañ mo¿e zostaæ wykonane w ró¿nym czasie\cite{kl_inne_alg_mrowkowe}. 

W tej metodzie, podobnie jak w metodzie do rozwi¹zania problemu plecakowego, nale¿y stworzyæ graf pe³ny z wierzcho³kami odpowiadaj¹cymi konkretnym zadaniom. Nastêpnie mrówki przechodz¹ przez wszystkie wierzcho³ki i zostawiaj¹ feromony. Czynnikiem decyduj¹cym o wyborze wierzcho³ków nadal jest zwi¹zana z feromonami. Do rozwi¹zania tego problemu nie jest brana pod uwagê liczba feromonów na krawêdzi pomiêdzy wierzcho³kiem a jego s¹siadami. Wykorzystywana jest natomiast suma feromonów na wszystkich krawêdziach do odwiedzanych wierzcho³ków z wierzcho³kami ju¿ odwiedzonymi.


\subsection{Algorytmy zach³anne}
	Kolejnym spojrzeniem na poruszany w pracy problem komiwoja¿era s¹ algorytmy zach³anne (ang. \textit{greedy algorithms}). Nie ³atwo znaleŸæ dowód na to czy dla podanego problemu algorytm zach³anny znalaz³ poprawny wynik, jednak stosuj¹c siê do pewnych zasad mo¿na okreœliæ, ¿e dla danego problemu istnieje rozwi¹zanie zach³anne. G³ówn¹ strategi¹ jak¹ siê kieruj¹ jak sama nazwa naprowadza jest dokonywanie wyborów, które w danej chwili wydaj¹ siê najlepsze. Oznacza to, ¿e dokonuje siê wyborów optymalnych lokalnie w nadziei, ¿e te wybory doprowadz¹ do rozwi¹zania globalnego w zadowalaj¹cym czasie. W odró¿nieniu do strategii zastosowanej w programowaniu dynamicznym wybory podejmowane przez algorytmy zach³anne nie s¹ uzale¿nione od wyborów przesz³ych. Kolejnym kryterium stosowanym do ocenienia poprawnoœci rozwi¹zania zach³annego jest w³asnoœæ optymalnej pod struktury, mówi¹ca o tym, ¿e optymalne rozwi¹zanie dla ca³ego problemu istnieje jedynie przy optymalnym rozwi¹zaniu pod problemów. Dane kryterium jest równie¿ istotne w przypadku rozwi¹zywania problemów metod¹ programowania dynamicznego. Algorytmy zach³anne nie zawsze prowadz¹ jednak do optymalnych rozwi¹zañ, jednak¿e dla w wiêkszoœci problemów daj¹ wystarczaj¹ce rezultaty.
	Skorzystanie z algorytmów zach³annych czêsto okazuje siê niewystarczaj¹ce. Aby uzyskaæ lepszy efekt i polepszyæ zbudowane ju¿ trasy mo¿emy wykorzystaæ algorytmy lokalnej optymalizacji (ang. \textit{local search}). U¿ycie ich na zwróconych przez algorytmy zach³anne trasach powinno zminimalizowaæ odleg³oœci miêdzy wierzcho³kami w celu poprawienia otrzymanego rozwi¹zania. Dok³adniejszy opis dzia³ania wybranych algorytmów zach³annych i metod optymalizuj¹cych zosta³ przedstawiony w podrozdzia³ach.
	
	Ju¿ w latach piêædziesi¹tych zosta³a zastosowana koncepcja algorytmów zach³annych do przeszukiwania grafów, gdzie Esdger Wybe Dijkstra d¹¿¹c do skrócenia tras w Amsterdamie, stolicy Holandii opracowa³ technikê do generowania minimalnych drzew rozpinaj¹cych. Równie¿ w tej samej dekadzie Robert Clay Prim oraz Joseph Bernard Kruskal opracowali strategie optymalizacji, które opiera³y siê na minimalizacji kosztów dla wa¿onych tras. Do dzisiaj stworzone algorytmy s¹ wykorzystywane w mapach geograficznych do wyznaczania najkrótszych œcie¿ek, do znajdowania OSPF (ang. \textit{Open Shortest Path First}) w protokole routingu IP (ang. \textit{Internet Protocol}) czy w sieciach telefonicznych.
	

