\chapter{Ogólny problem}
Badany przez nas problem jest w informatyce nazywany problemem komiwoja¿era. W tym rozdziale zostanie on omówiony oraz metody optymalizacji. Problem komiwoja¿era (ang. travelling salesman problem - TSP) nale¿y do rodziny problemów NP-trudnych. Znalezienie najlepszego rozwi¹zania jest trudne i fascynuje naukowców od wielu lat. Niektórzy poddaj¹ pod w¹tpliwoœæ znalezienie efektywnego rozwi¹zania, czyli takiego którego czas dzia³ania jest maksymalnie wielomianowy. Aktualnie istnieje wiele rozwi¹zañ tego problemu, a proponowane podejœcia s¹ bardzo interesuj¹ce. Niektóre z nich bazuj¹ na lokalnych przeszukiwaniach grafu, a inne opieraj¹ siê na przyk³adach które wystêpuj¹ w przyrodzie.

Podobnym problemem do TSP jest problem konika szachowego. Problem ten równie¿ nale¿y do rodziny problemów NP-zupe³nym. Ju¿ w XVIII wieku badania nad tym problemem rozpocz¹³ Euler. Rozwi¹zanie tego problemu polega na znalezieniu œcie¿ki jak¹ ma przebyæ konik szachowy, tak aby odwiedziæ ka¿de pole na szachownicy tylko i wy³¹cznie raz. Skoczek porusza siê po planszy zgodnie z okreœlonym ruchem, a plansza szachowa mo¿e mieæ ró¿ny rozmiar. Konik porusza siê a¿ do momentu odwiedzenia wszystkich pól lub do momentu w którym nie ma mo¿liwoœci odwiedzenia kolejnego pola.

Optymalizacja tras od zawsze jest obecna w historii ludzkoœci. Nawet takie trywialne problemy jak podró¿ pomiêdzy 3 miejscowoœciami mo¿e zostaæ sklasyfikowany jako problem komiwoja¿era. Chocia¿ dok³adne wskazanie na Ÿród³o problemu TSP nie jest znane, to ju¿ w 1832 roku w przewodniku dla podró¿uj¹cych po Niemczech i Szwajcarii zosta³a zawarta informacja o optymalizacji trasy przejazdu. Nie ma tam zawartych ¿adnych teorii matematycznych w zwi¹zku z czym nie mo¿na uznaæ tego dzie³a za pocz¹tek rozwa¿añ nad problemem komiwoja¿era.\cite{kl_poczatek_rozwazan}

W XIX wieku William Hamilton stworzy³ fundamenty pod definicjê TSP. W rozwi¹zaniu problemu komiwoja¿era nale¿y znaleŸæ cykl w grafie. W sk³ad takiego cyklu musi zostaæ zawarty ka¿dy z wierzcho³ków. Ka¿dy z wierzcho³ków mo¿e znajdowaæ siê w rozwi¹zaniu dok³adnie tylko raz. Cykl który spe³nia wymieniony warunek jest cyklem Hamiltona. Jeœli w grafie mo¿na wyró¿niæ cykl z opisanymi powy¿ej warunkami, to graf jest grafem Hamiltonowskim. 

Na \ref{kl_graf_nie_hamiltona} zosta³ przedstawiony graf bez cyklu Hamiltona. W grafie tym nie mo¿na znaleŸæ takiego po³¹czenia które zawiera wszystkie wierzcho³ki przechodz¹c przez ka¿dy z nich dok³adnie raz. Istnieje mo¿liwoœæ przejœcia przez wszystkie wierzcho³ki jedynie po powtórnym odwiedzeniu przynajmniej jednego wierzcho³ka.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_graf_nie_hamiltona.png}
	\caption{Graf bez cyklu Hamiltona.}
	\label{kl_graf_nie_hamiltona}
\end{figure}

Graf z \ref{kl_graf_hamiltona} posiada po³¹czenie krawêdzi dziêki któremu mo¿na przejœæ po wszystkich wierzcho³kach dok³adnie raz. Takie przejœcie jest w³aœnie cyklem Hamiltona w zwi¹zku z czym graf jest Hamiltonowski. Wyruszaj¹c przyk³adowo z punktu F mo¿emy przejœæ kolejno do E - G - D - B - A - C. W ten sposób odwiedzimy wszystkie wierzcho³ki tylko raz. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_graf_hamiltona.png}
	\caption{Graf z cyklem Hamiltona.}
	\label{kl_graf_hamiltona}
\end{figure}

W latach 30 XX wieku Merrill Meeks Flood rozpocz¹³ rozwa¿ania nad optymalizacj¹ przejazdu autobusów szkolnych. Dzia³alnoœæ t¹ mo¿emy uznaæ za pocz¹tek pracy nad problemem TSP. Wraz z up³ywem czasu zainteresowanie problemem optymalizacyjnym narasta³o, a co za tym idzie powstawa³y nowe pomys³y na algorytmy. Jednak ¿aden z pomys³ów nie jest w stanie zaproponowaæ dok³adnego rozwi¹zania które jest w stanie przedstawiæ rezultat w czasie wyra¿onym za pomoc¹ wielomianu.

\section{Metody optymalizacji} 
	
Jednym z proponowanych rozwi¹zañ jest algorytm Helda Karpa który jest oparty na programowaniu dynamicznym. Z³o¿onoœæ pamiêciowa tego algorytmy wynosi $\theta$(\(2n^n\))
, a czasowa $\theta$(\(n^2*2^n\)). W algorytmie tym na ka¿dym kroku wyznaczamy punkt który powinien byæ przedostatni na trasie. Aby wyznaczyæ poprzednika nale¿y skorzystaæ ze wzoru w którym poszukiwana jest najmniejsza wartoœæ pomiêdzy punktami.

Innym przyk³adem , który mo¿na wykorzystaæ do rozwi¹zania problemu komiwoja¿era jest algorytm najbli¿szego s¹siada. Rozwi¹zanie to wykorzystuje strategiê zach³ann¹. W algorytmie szukamy aktualnie najlepszego ruchu. W tym celu przeszukiwani s¹ jedynie s¹siedzi którzy s¹ najbli¿ej aktualnego punktu. Z³o¿onoœæ takiego algorytmu jest szacowana na $\theta$(\(n^2\)).

Oprócz standardowych przeszukiwañ zbiorów na przestrzeni lat pojawi³y siê propozycje które wprowadzaj¹ elementy losowoœci. Przyk³adem takiego rozwi¹zania mogê byæ algorytm genetyczny oraz algorytm mrówkowy. Nale¿¹ one do grup algorytmów heurystycznych, czyli do takich, które nie daj¹ gwarancji znalezienia dok³adnego rozwi¹zania.

W pracy zostan¹ zbadane rozwi¹zania problemu za pomoc¹ algorytmu genetycznego, mrówkowego oraz zach³annego. W pozosta³ych podrozdzia³ach zostan¹ opisane ich klasyczne wersje.

\subsection{Algorytm genetyczny - Pawe³}
Algorytm genetyczny(ang. Genetic Algorithm - GA) polega na symulacji procesów genetycznych. W przyrodzie czêsto najs³absze osobniki, nie bior¹ udzia³u w reprodukcji, przez co nie mog¹ przekazaæ swoich s³abych genów potomkom. Podobnie w algorytmie genetycznym populacja poddawana jest operatorom genetycznym: selekcja najlepszych osobników, krzy¿owanie oraz mutacja. Algorytm d¹¿y do tego, aby pocz¹tkowe pokolenia z kolejnymi iteracjami ewoluowa³y w coraz to lepsze rozwi¹zania. Algorytm zawiera wiele elementów losowych np. rozmiar populacji, iloœæ pokoleñ lub prawdopodobieñstwo krzy¿owani/mutacji. Te czynniki powoduj¹, ¿e wyniki za ka¿dym razem mog¹ zdarzaæ siê inne. Wszystko zale¿y od z³o¿onoœci badanego problemu oraz danych.\cite{genetic_2}. 
 
Algorytmy genetyczne s¹ od dawna stosowane informatyce do rozwi¹zywania problemów komiwoja¿era oraz innych NP trudnych zagadnieñ.  Pionierem algorytmów genetycznych by³ John Henry Holland\cite{genetic_1}, który w latach 70 napisa³ ksi¹¿kê o algorytmach ewolucyjnych "Adaptation in Natural and Artificial Systems". Medycyna jest jedn¹ z wa¿niejszych dziedzin, gdzie wykorzystuje siê algorytmy genetyczne. Zbiory danych i przestrzeñ przeszukiwañ jest ogromna i z³o¿ona. Zazwyczaj w oparciu o te informacjê, lekarz musi podj¹æ decyzjê, czy np. nowotwór jest z³oœliwy, czy ma ³agodny przebieg. Algorytm genetyczny pozwala wspomóc lekarza przy podejmowania takich decyzji, przetwarzaj¹c i analizuj¹c te ogromne zbiory. \cite{genetic_2}. Kolejn¹ ga³êzi¹ gospodarki, w których zastosowanie znajduje algorytm genetyczny, jest przemys³ spo¿ywczy, a konkretnie optymalizacja linii produkcyjnych. Za ich pomoc¹ algorytmu genetycznego wyznacza siê parametry takie jak temperatura, ciœnieniu lub zapotrzebowanie mocy. Dziêki temu wszystkie procesy technologiczne zachodz¹ce w maszynach i urz¹dzeniach s¹ wydajne i zoptymalizowane\cite{genetic_4}. Algorytmy genetyczne czêsto stosuje siê jako  wskazanie punktów pocz¹tkowych w innych metodach optymalizacyjnych. Poza podanymi przyk³adami, znajduj¹ one zastosowanie praktycznie wszêdzie: ekonomia, gie³da, przemys³ lotniczy, kombinatoryka, sieci komputerowe, zarz¹dzanie ³añcuchem dostaw a tak¿e ustalanie czasu reklamy w telewizji \cite{genetic_5}.

	Przed przejœciem do omawiania algorytmu, nale¿y wyjaœniæ podstawowe pojêcia, które wystêpuj¹ w algorytmie genetycznym:
\begin{description}[font=$\bullet$~\normalfont\scshape]
 \item[Osobnik] pojedyncze rozwi¹zanie problemu, zakodowane w postaci chromosomu.
 \item[Populacja]zbiór osobników o sta³ej liczbie $N$ w przekroju trwania ca³ego algorytmu.
 \item[Gen] przechowuje informacjê o dowolnej cesze osobnika. W zale¿noœci od sposobu kodowania mo¿e to byæ bit, dowolna cyfra, znak itp.
 \item[Chromosom] sk³ada siê z uporz¹dkowanego ci¹gu genów, przechowuje wszystkie cechy osobnika
 \item[Genotyp] w przyrodzie mo¿e sk³adaæ siê z kilku chromosomów i okreœla sk³ad osobnika. W algorytmach genetycznych przyjmuje siê, ¿e jest to pojedynczy chromosom \cite{genetic_1}.
 \item[Funkcja przystosowania]
\end{description} 
 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/algorytm_genetyczny.png}
	\caption{Schemat algorytmu genetycznego}
	\label{genetic}
\end{figure}
	
	Schemat blokowy klasycznego algorytm genetycznego zosta³ pokazany na rysunku \ref{genetic}
	
Pierwszym krokiem  jest wylosowanie populacji pocz¹tkowej algorytmu. Wielkoœæ populacji podczas trwania ca³ego algorytmu jest sta³a $N$. Wa¿ne jest, aby wszystkie osobniki by³y jak najbardziej zró¿nicowane i wygenerowane losowo. Ka¿dy z nich nastêpnie musi zostaæ zakodowany do postaci chromosomów, które bêd¹ przechowywaæ w sobie informacjê o odwiedzanych punktach w postaci genów.
	
W populacji ka¿dy osobnik musi zostaæ poddany ocenie funkcji przystosowania. Jej wynik determinuje jak dobre jest dane rozwi¹zanie. W klasycznym algorytmie d¹¿y siê do maksymalizacji tej funkcji. Okreœlenie jak dana funkcja przystosowania bêdzie wygl¹daæ, jest to jedn¹ z najwa¿niejszych czêœci algorytmu genetycznego. Jeœli zostanie Ÿle zdefiniowana, znalezione osobnik mo¿e nie spe³niaæ wymagañ rozwi¹zania problemu.
	
Po ocenie osobników zostaje sprawdzony warunek koñcowy algorytmu. W zale¿noœci od problemu zostaje zdefiniowany inny warunek. W klasycznych podejœciach s¹ dwa rodzaje warunków koñcowych. Pierwszym popularnym warunkiem koñcowym jest sta³a iloœæ iteracji algorytmu, czyli po wykonaniu okreœlonej iloœci razy ewolucji, wybierany jest najlepszy osobnik z populacji. Drugim warunkiem zazwyczaj jest przetwarzanie algorytmu dopóki nie zostanie znaleziony dostatecznie dobry osobnik. Nale¿y równie¿ za³o¿yæ, ¿e jeœli w kolejnych pokoleniach nie zachodzi poprawa najlepszego rozwi¹zania, nale¿y przerwaæ. Wybór  w jaki sposób bêdzie wygl¹daæ warunek koñcowy zale¿y od wielu czynników. Jeœli wa¿ny jest krótki czas, nale¿y za³o¿yæ pierwszy wariant. Jeœli natomiast algorytm mo¿e szukaæ rozwi¹zania nawet kilka godzin, mo¿na przyj¹æ drugi wariant.
	
Kolejnym krokiem algorytmu jest wyselekcjonowanie rodziców do reprodukcji. Polega ona na tym, ¿e osobniki lepsze(maj¹ wiêksz¹ wartoœæ oceny przystosowania)maj¹ wiêksze szansê na pozostanie rodzicem i przekazanie swoich cech. \cite{genetic_3}. Najpopularniejszymi metodami wyboru rodziców jest metoda ruletki oraz turniejowa.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/ag_kolowy.png}
	\caption{Metoda ruletki}
	\label{ruletka}
\end{figure}
Na rysunku \ref{ruletka} zosta³a zilustrowana pierwsza metoda ruletki. Ka¿dy z osobników dostaje wirtualny wycinek ko³a fortuny. Jego wielkoœæ zale¿y od wartoœci funkcji prawdopodobieñstwa. Przy ka¿dym wyborze rodzica nastêpuje zakrêceniem ko³a i do reprodukcji zostaje wybrany osobnik na który bêdzie wskazywa³ sta³y punkt. 
	
W metodzie turniejowej zostaje wybranych $r$ osobników z populacji $N$. Z poœród nich zostaje wybrany zwyciêzca(najwiêksza wartoœæ funkcji przystosowania), który trafia do puli rodzicielskiej. Im wiêksza jest iloœæ osobników $r$ tym mniejsze szanse, ¿e s³absze osobniki zostan¹ wybrane.
	
Wybrani rodzice zostaj¹ poddani operatorom genetycznym: krzy¿owanie(ang. crossover) oraz mutacji(ang. mutation). Krzy¿owanie polega na po³¹czeniu czêœci chromosomu jednego rodzica z czêœci¹ drugiego. Wynikiem takiego po³¹czenia jest nowy osobnik. Proces krzy¿owania w zale¿noœci mo¿e przebiegaæ w ró¿ny ale zawsze okreœlony sposób. Wszystko zale¿y od metody zakodowania chromosomu oraz od tego czy kolejnoœæ genów i ich unikalnoœæ ma znaczenie. W klasycznym podejœciu polega na rozciêciu w dowolnym miejscu genotypu u dwóch osobników oraz skrzy¿owaniu ich ze sob¹ w tym punkcie(rys. \ref{crossover}).
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/ag_krzyzowanie.png}
	\caption{Klasyczne krzy¿owanie}
	\label{crossover}
\end{figure}	
	 Nastêpnie u nowego osobnika mo¿e z prawdopodobieñstwem $pm$ wyst¹piæ mutacja. Jest to zmiana dowolnego pojedynczego rys \ref{mutacja} lub ci¹gu genów na inny. Wartoœæ $pm$ w klasycznych algorytmach jest stosunkowo niskie. Mutacja ma na celu delikatne zró¿nicowanie osobników w celu przeszukania nowej przestrzeni rozwi¹zañ. Natomiast gdyby zachodzi³a czêsto, mog³aby powodowaæ niszczenie dobrych rozwi¹zañ.
	 \begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/ag_mutacja.png}
	\caption{Mutacja genotypu}
	\label{mutacja}
\end{figure}	
	
	Po zastosowaniu wszystkich operatorów genetycznych, nowa populacja jest poddawana ocenie przystosowania i jeœli wyst¹pi³ warunek koñcowy, wybierane jest najlepsze rozwi¹zanie.
	Algorytmy genetyczne i jego odmiany zrewolucjonizowa³y systemy informatyczne. Nie s¹ one algorytmami, które wyliczaj¹ dok³adne wyniki, ale przy odpowiedniej implementacji i ustaleniu parametrów wyjœciowych, pozwalaj¹ osi¹gn¹æ wystarczaj¹ce rezultaty. Bardzo wa¿ny jest czas znalezienia takiego rozwi¹zania. Jeœli rozwi¹zanie idealne obliczane jest w ci¹gu 24 godzin przez algorytm dok³adny, a algorytm genetyczny w trakcie kilku minut znajdzie rozwi¹zanie bêd¹ce w s¹siedztwie, swoj¹ efektywnoœci¹ wygra ten drugi, gdy¿ u¿ytkownik, nie bêdzie chcia³ czekaæ ca³ej doby na wynik swojego zapytania. Oczywiœcie, algorytmy genetyczne te¿ mog¹ znaleŸæ najlepsze rozwi¹zanie. Kwesti¹ ograniczenia jest zawsze czas.


\subsection{Algorytm mrówkowy}

Obserwacje nad zachowaniami w przyrodzie wielokrotnie mia³y wp³yw na rozwój nowych rozwi¹zañ. Tak jak w przypadku algorytmu genetycznego, tak i w przypadku algorytmu mrówkowego pomys³ zosta³ zaczerpniêty z przyrody. Dok³adne dzia³anie algorytmu mrówkowego wzoruje siê na zachowaniu kolonii mrówek. Dziêki pracy zespo³owej, owady te s¹ w stanie wypracowaæ optymaln¹ œcie¿kê miêdzy siedliskiem a znalezionym pokarmem.

Dla niejednego gatunku problematyczne mog³oby byæ odtworzenie przebytej œcie¿ki. Na pocz¹tku nale¿a³oby zadaæ sobie pytanie w jaki sposób te niewielkich rozmiarów owady s¹ w stanie znacz¹co u³atwiæ sobie przetrwanie? Istotn¹ rolê odgrywa tutaj wspomniana ju¿ praca zespo³owa. To dziêki niej mrówki s¹ w stanie optymalizowaæ trasê. Innym wa¿nym czynnikiem determinuj¹cym poprawê œcie¿ki jest zapach jaki zostawiaj¹ mrówki. 

Zapach nie jest niczym innym jak feromonem wytwarzanym przez mrówki. Dziêki pozostawionemu zapachowi mrówki identyfikuj¹ w jaki sposób poruszali siê ich poprzednicy w zwi¹zku z czym odtworzenie trasy nie stanowi³o ju¿ powa¿nego problemu. Przy kolejnych iteracjach, kolonia próbuje optymalizowaæ aktualn¹ trasê. W tym celu równie¿ wykorzystuje zapach pozostawiony w poprzednich przejœciach. Œcie¿ka jest losowo zmieniana w celu optymalizacji. Jeœli modyfikacja przynios³a oczekiwany efekt, to trasa zostaje zmieniona.

Algorytm mrówkowy znajduje swoje zastosowanie w rozwi¹zywaniu innych problemów. Problem plecakowy jest jednym z takich przyk³adów. Pojawia siê on najczêœciej przy optymalnym zarz¹dzaniu zasobami. Mamy dany zbiór jakichœ przedmiotów z czego ka¿dy z nich posiada okreœlony ciê¿ar i wartoœæ. Do plecaka musimy za³adowaæ przedmioty o jak najwiêkszej wartoœci. Naszym ograniczeniem jest jednak ³¹czny ciê¿ar przedmiotów które mo¿emy udŸwign¹æ. 

Algorytm mrówkowy wygl¹da bardzo podobnie w tym przypadku. Na pocz¹tku jest $N$ agentów - mrówek. Ka¿dy agent iteracyjnie poszukuje jak najlepszego rozwi¹zania. Po ka¿dej iteracji mo¿na wyró¿niæ trzy typy rozwi¹zañ: rozwi¹zanie poœrednie, rozwi¹zanie czêœciowe lub stan. Agenci w celu znalezienia rozwi¹zania wykorzystuj¹ swoje naturalne umiejêtnoœci czyli zostawiaj¹ na wszystkich obiektach w plecaku feromony. Dziêki lotnoœci feromonów mrówki s¹ w stanie identyfikowaæ bardziej zadowalaj¹ce przedmioty.

Krzysztof Schiff w artykule Ant colony optimization algorithm for the 0-1 knapsack\cite{kl_alg_plecakowy} przedstawi³ rozwi¹zanie problemu plecakowego. Do wyboru najlepszego rozwi¹zania wykorzystane zosta³y trzy metody. Zgodnie z przyjêt¹ konwencj¹ przez autora artyku³u metody maj¹ odpowiednie nazwy: AKA1, AKA2 oraz AKA3. Za wybór najlepszego rozwi¹zania odpowiadaj¹ wzory: 
	\[
	    AKA1 = \frac{z}{\frac{w}{V}}
	\]
	\[
	    AKA2 = \frac{z}{w^2}
	\]
	\[
	    AKA3 = \frac{z}{\frac{w}{C}}
	\]
gdzie:\\
-- z jest zyskiem wybranego obiektu;\\
-- w jest wag¹ wybranego obiektu;\\
-- V jest aktualn¹ ³adownoœci¹ plecaka;\\
-- z jest zyskiem wybranego obiektu;\\
-- C jest ca³kowit¹ wag¹ plecaka.\\

Problem komiwoja¿era i problem plecakowy s¹ problemami kombinatorycznymi. Ich rozwi¹zanie polega na poszukiwaniu optymalnej œcie¿ki na grafie pe³nym. Inna odmian¹ problemu jest kolorowania grafu. W tej wariacji problem jest od razu zadany na grafie. Dla wszystkich wierzcho³ków w grafie nale¿y dobraæ takie kolory, aby ¿adne dwa s¹siednie wierzcho³ki nie mia³y tego samego koloru \cite{kl_inne_alg_mrowkowe}. 

Mrówki nie dzia³aj¹ bezpoœrednio na grafie pocz¹tkowym poniewa¿ graf ten nie musi byæ grafem pe³nym. Nale¿y stworzyæ dla mrówek alternatywê podobn¹ do orygina³u z zachowaniem takiego samego zbioru wierzcho³ków ale z pe³nymi krawêdziami. Nastêpnie nale¿y dobraæ numeryczne wartoœci odpowiadaj¹ce konkretnym kolorom. Jeœli mrówka odwiedzi dany wierzcho³ek, to zostaje on pokolorowany na najni¿szy kolor który nie zosta³ dotychczas u¿yty do kolorowania któregoœ z s¹siadów.

Tak jak w przypadku poprzednich algorytmów wykorzystywane s¹ zapachy pozostawiane przez mrówki. Iloœæ u¿ytych unikalnych kolorów by³aby odwrotnie proporcjonalna do iloœci feromonów. W efekcie czego heurystyka by³aby odwrotnie proporcjonalna do wykorzystanych kolorów po kolejnych iteracjach. Wynikiem tych operacji bêdzie rozwi¹zanie w którym, w grafie oryginalnym ka¿dy wierzcho³ek bêdzie odwiedzany tylko raz.

Ostatni z przyk³adów wykorzystania algorytmu mrówkowego jest harmonogram produkcji. W porównaniu do poprzednich metod w tym algorytmie zachodzi pewna modyfikacja. G³ównym problemem w harmonogramie produkcji jest znalezienie takiej kolejnoœci przetwarzanych zadañ, aby jak najszybciej je przetworzyæ. Aby lepiej zobrazowaæ t¹ sytuacjê nale¿y sobie wyobraziæ fabrykê w której znajduj¹ siê linie produkcyjne. Na linii s¹ przetwarzane zadania w odpowiedniej kolejnoœci oraz ka¿de z zadañ mo¿e zostaæ wykonane w ró¿nym czasie\cite{kl_inne_alg_mrowkowe}. 

W tej metodzie, podobnie jak w metodzie do rozwi¹zania problemu plecakowego, nale¿y stworzyæ graf pe³ny z wierzcho³kami odpowiadaj¹cymi konkretnym zadaniom. Nastêpnie mrówki przechodz¹ przez wszystkie wierzcho³ki i zostawiaj¹ feromony. Czynnikiem decyduj¹cym o wyborze wierzcho³ków nadal jest zwi¹zana z feromonami. Do rozwi¹zania tego problemu nie jest brana pod uwagê liczba feromonów na krawêdzi pomiêdzy wierzcho³kiem a jego s¹siadami. Wykorzystywana jest natomiast suma feromonów na wszystkich krawêdziach do odwiedzanych wierzcho³ków z wierzcho³kami ju¿ odwiedzonymi.


\subsection{Algorytmy zach³anne}
	Kolejnym spojrzeniem na poruszany w pracy problem komiwoja¿era s¹ algorytmy zach³anne (ang. greedy algorithms). Nie znajdziemy dowodu na to czy dla podanego problemu algorytm zach³anny znalaz³ poprawny wynik, jednak stosuj¹c siê do pewnych zasad mo¿emy okreœliæ, ¿e dla naszego problemu istnieje rozwi¹zanie zach³anne. G³ówn¹ strategi¹ jak¹ siê kieruj¹ jak sama nazwa wskazuje jest dokonywanie wyborów, które w danej chwili wydaj¹ siê najlepsze. Oznacza to, ¿e dokonuje siê wyborów optymalnych lokalnie w nadziei, ¿e te wybory doprowadz¹ do rozwi¹zania globalnego w rozs¹dnym czasie. W odró¿nieniu do strategii zastosowanej w programowaniu dynamicznym wybory podejmowane przez algorytmy zach³anne nie s¹ uzale¿nione od wyborów przesz³ych. Kolejnym kryterium stosowanym do ocenienia poprawnoœci rozwi¹zania zach³annego jest w³asnoœæ optymalnej pod struktury, mówi¹ca o tym, ¿e optymalne rozwi¹zanie dla ca³ego problemu istnieje jedynie przy optymalnym rozwi¹zaniu pod problemów. Dane kryterium jest równie¿ istotne w przypadku rozwi¹zywania problemów metod¹ programowania dynamicznego. Algorytmy zach³anne nie zawsze prowadz¹ jednak do optymalnych rozwi¹zañ, jednak¿e dla w wiêkszoœci problemów daj¹ wystarczaj¹ce rezultaty.
	Skorzystanie z algorytmów zach³annych czêsto okazuje siê niewystarczaj¹ce. Aby uzyskaæ lepszy efekt i polepszyæ zbudowane ju¿ trasy mo¿emy wykorzystaæ algorytmy lokalnej optymalizacji (ang. local search). U¿ycie ich na zwróconych przez algorytmy zach³anne trasach powinno zminimalizowaæ odleg³oœci miêdzy wierzcho³kami w celu poprawienia otrzymanego rozwi¹zania. Dok³adniejszy opis dzia³ania wybranych algorytmów zach³annych i metod optymalizuj¹cych zosta³ przedstawiony w podrozdzia³ach.
	

