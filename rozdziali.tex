\chapter{Ogólny problem}

Badany przez nas problem jest w informatyce nazywany problemem komiwoja¿era. W tym rozdziale zostanie on omówiony oraz metody optymalizacji.

\section{Problem komiwoja¿era} 
Problem komiwoja¿era (ang. travelling salesman problem - TSP) nale¿y do rodziny problemów NP-trudnych. Znalezienie najlepszego rozwi¹zania jest trudne i fascynuje naukowców od wielu lat. Niektórzy poddaj¹ pod w¹tpliwoœæ znalezienie efektywnego rozwi¹zania, czyli takiego którego czas dzia³ania jest maksymalnie wielomianowy. Aktualnie istnieje wiele rozwi¹zañ tego problemu, a proponowane podejœcia s¹ bardzo interesuj¹ce. Niektóre z nich bazuj¹ na lokalnych przeszukiwaniach grafu, a inne opieraj¹ siê na przyk³adach które wystêpuj¹ w przyrodzie.

Podobnym problemem do TSP jest problem konika szachowego. Problem ten równie¿ nale¿y do rodziny problemów NP-zupe³nym. Ju¿ w XVIII wieku badania nad tym problemem rozpocz¹³ Euler. Rozwi¹zanie tego problemu polega na znalezieniu œcie¿ki jak¹ ma przebyæ konik szachowy, tak aby odwiedziæ ka¿de pole na szachownicy tylko i wy³¹cznie raz. Skoczek porusza siê po planszy zgodnie z okreœlonym ruchem, a plansza szachowa mo¿e mieæ ró¿ny rozmiar. Konik porusza siê a¿ do momentu odwiedzenia wszystkich pól lub do momentu w którym nie ma mo¿liwoœci odwiedzenia kolejnego pola.

Optymalizacja tras od zawsze jest obecna w historii ludzkoœci. Nawet takie trywialne problemy jak podró¿ pomiêdzy 3 miejscowoœciami mo¿e zostaæ sklasyfikowany jako problem komiwoja¿era. Chocia¿ dok³adne wskazanie na Ÿród³o problemu TSP nie jest znane, to ju¿ w 1832 roku w przewodniku dla podró¿uj¹cych po Niemczech i Szwajcarii zosta³a zawarta informacja o optymalizacji trasy przejazdu. Nie ma tam zawartych ¿adnych teorii matematycznych w zwi¹zku z czym nie mo¿na uznaæ tego dzie³a za pocz¹tek rozwa¿añ nad problemem komiwoja¿era.\cite{kl_poczatek_rozwazan}

W XIX wieku William Hamilton stworzy³ fundamenty pod definicjê TSP. W rozwi¹zaniu problemu komiwoja¿era nale¿y znaleŸæ cykl w grafie. W sk³ad takiego cyklu musi zostaæ zawarty ka¿dy z wierzcho³ków. Ka¿dy z wierzcho³ków mo¿e znajdowaæ siê w rozwi¹zaniu dok³adnie tylko raz. Cykl który spe³nia wymieniony warunek jest cyklem Hamiltona. Jeœli w grafie mo¿na wyró¿niæ cykl z opisanymi powy¿ej warunkami, to graf jest grafem Hamiltonowskim. 

Na \ref{kl_graf_nie_hamiltona} zosta³ przedstawiony graf bez cyklu Hamiltona. W grafie tym nie mo¿na znaleŸæ takiego po³¹czenia które zawiera wszystkie wierzcho³ki przechodz¹c przez ka¿dy z nich dok³adnie raz. Istnieje mo¿liwoœæ przejœcia przez wszystkie wierzcho³ki jedynie po powtórnym odwiedzeniu przynajmniej jednego wierzcho³ka.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_graf_nie_hamiltona.png}
	\caption{Graf bez cyklu Hamiltona.}
	\label{kl_graf_nie_hamiltona}
\end{figure}

Graf z \ref{kl_graf_hamiltona} posiada po³¹czenie krawêdzi dziêki któremu mo¿na przejœæ po wszystkich wierzcho³kach dok³adnie raz. Takie przejœcie jest w³aœnie cyklem Hamiltona w zwi¹zku z czym graf jest Hamiltonowski. Wyruszaj¹c przyk³adowo z punktu F mo¿emy przejœæ kolejno do E - G - D - B - A - C. W ten sposób odwiedzimy wszystkie wierzcho³ki tylko raz. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_graf_hamiltona.png}
	\caption{Graf z cyklem Hamiltona.}
	\label{kl_graf_hamiltona}
\end{figure}

W latach 30 XX wieku Merrill Meeks Flood rozpocz¹³ rozwa¿ania nad optymalizacj¹ przejazdu autobusów szkolnych. Dzia³alnoœæ t¹ mo¿emy uznaæ za pocz¹tek pracy nad problemem TSP. Wraz z up³ywem czasu zainteresowanie problemem optymalizacyjnym narasta³o, a co za tym idzie powstawa³y nowe pomys³y na algorytmy. Jednak ¿aden z pomys³ów nie jest w stanie zaproponowaæ dok³adnego rozwi¹zania które jest w stanie przedstawiæ rezultat w czasie wyra¿onym za pomoc¹ wielomianu.

\section{Metody optymalizacji} 
	
Jednym z proponowanych rozwi¹zañ jest algorytm Helda Karpa który jest oparty na programowaniu dynamicznym. Z³o¿onoœæ pamiêciowa tego algorytmy wynosi O(n razy 2 do n), a czasowa O(n do 2 razy 2 do n). W algorytmie tym na ka¿dym kroku wyznaczamy punkt który powinien byæ przedostatni na trasie. Aby wyznaczyæ poprzednika nale¿y skorzystaæ ze wzoru w którym poszukiwana jest najmniejsza wartoœæ pomiêdzy punktami.

Innym przyk³adem , który mo¿na wykorzystaæ do rozwi¹zania problemu komiwoja¿era jest algorytm najbli¿szego s¹siada. Rozwi¹zanie to wykorzystuje strategiê zach³ann¹. W algorytmie szukamy aktualnie najlepszego ruchu. W tym celu przeszukiwani s¹ jedynie s¹siedzi którzy s¹ najbli¿ej aktualnego punktu. Z³o¿onoœæ takiego algorytmu jest szacowana na O(n do 2).

Oprócz standardowych przeszukiwañ zbiorów na przestrzeni lat pojawi³y siê propozycje które wprowadzaj¹ elementy losowoœci. Przyk³adem takiego rozwi¹zania mogê byæ algorytm genetyczny oraz algorytm mrówkowy. Nale¿¹ one do grup algorytmów heurystycznych, czyli do takich, które nie daj¹ gwarancji znalezienia dok³adnego rozwi¹zania.

W pracy zostan¹ zbadane rozwi¹zania problemu za pomoc¹ algorytmu genetycznego, mrówkowego oraz zach³annego. W pozosta³ych podrozdzia³ach zostan¹ opisane ich klasyczne wersje.

\subsection{Algorytm genetyczny - Pawe³}
Algorytm genetyczny (ang.  \textit{GA - Genetic Algorithm}) polega na symulacji procesów genetycznych zachodz¹cych w populacjach osobników, stosuje siê je g³ównie przy zadaniach optymalizacyjnych. W przyrodzie wiêkszoœæ gatunków od wieków, w tym przede wszystkim i cz³owiek, w kolejnych swoich pokoleniach siê rozwinê³o i dostosowa³o do otaczaj¹cych warunków na œwiecie. Gdy jakiœ osobnik urodzi siê z cech¹, która jest przydatna w przetrwaniu, przeka¿ê tê cechê kolejnym pokoleniom. Najs³absze osobniki w populacji maj¹ zarówno mniejsze szanse na przetrwanie oraz rozmno¿enie, czyli przekazanie swoich cech potomkom. W przyrodzie zazwyczaj silniejsi wygrywaj¹. W latach 50 XX wieku zaczêto symulowaæ te procesy w informatyce. W latach 60 John Henry Holland zastosowa³ algorytm genetyczny przy pracach nad systemami adaptacyjnymi, a 1975  wyda³ ksi¹¿kê \textit{Adaptation in Natural and Artificial Systems}, w której to opisa³.\cite{genetic_1}. Algorytm genetyczny poszukuje najlepsze rozwi¹zania, wœród populacji potencjalnych rozwi¹zañ. Jest to g³ówna cecha, która odró¿nia go od tradycyjnych metod optymalizacji. Ka¿de rozwi¹zanie ulega ocenie na podstawie jego dopasowania do problemu - funkcja przystosowania. Algorytm na populacji symuluje zjawiska ewolucyjne, krzy¿uj¹c i mutuj¹c rozwi¹zania, stosuj¹c probabilistyczne regu³y wyboru. W ka¿dym takim nowym pokoleniu najs³absi s¹ usuwani, wiêc w kolejnych etapach populacja sk³ada siê z coraz to lepszych rozwi¹zañ \cite{genetic_9}. Kolejne pokolenia s¹ generowane, a¿ zostanie spe³niony warunek zakoñczenia. Mo¿e to byæ z góry ustalony czas trwania, iloœæ kolejnych pokoleñ lub brak poprawy wœród nowych rozwi¹zañ.

Algorytmy genetyczne i jego odmiany zrewolucjonizowa³y systemy informatyczne. Nie s¹ one algorytmami, które wyliczaj¹ dok³adne wyniki, ale przy odpowiedniej implementacji i ustaleniu parametrów wejœciowych, pozwalaj¹ osi¹gn¹æ dobre rezultaty. Bardzo wa¿ny jest czas znalezienia takiego rozwi¹zania. Jeœli rozwi¹zanie idealne obliczane jest przez algorytm tradycyjny w ci¹gu 24 godziny, a algorytm genetyczny w trakcie kilku minut znajdzie rozwi¹zanie bêd¹ce w s¹siedztwie, swoj¹ efektywnoœci¹ wygra ten drugi.  U¿ytkownik nie bêdzie chcia³ czekaæ ca³ej doby na wynik swojego zapytania. Oczywiœcie, algorytmy genetyczne te¿ mog¹ znaleŸæ najlepsze rozwi¹zanie. Kwesti¹ ograniczenia jest zawsze czas.

Medycyna jest jedn¹ z wa¿niejszych dziedzin, gdzie wykorzystuje siê algorytmy genetyczne. Zbiory danych i przestrzeñ przeszukiwañ jest ogromna i z³o¿ona. Zazwyczaj w oparciu o te informacjê, lekarz musi podj¹æ decyzjê, czy np. nowotwór jest z³oœliwy, czy ma ³agodny przebieg. Algorytm genetyczny pozwala wspomóc lekarza przy podejmowania takich decyzji, przetwarzaj¹c i analizuj¹c te ogromne zbiory. \cite{genetic_2}. Kolejn¹ ga³êzi¹ gospodarki, w których zastosowanie znajduje algorytm genetyczny, jest przemys³ spo¿ywczy, a konkretnie optymalizacja linii produkcyjnych. Za ich pomoc¹ algorytmu genetycznego wyznacza siê parametry takie jak temperatura, ciœnieniu lub zapotrzebowanie mocy. Dziêki temu wszystkie procesy technologiczne zachodz¹ce w maszynach i urz¹dzeniach s¹ wydajne i zoptymalizowane\cite{genetic_4}. Algorytmy genetyczne czêsto stosuje siê jako  wskazanie punktów pocz¹tkowych w innych metodach optymalizacyjnych. Poza podanymi przyk³adami, znajduj¹ one zastosowanie praktycznie wszêdzie: ekonomia, gie³da, przemys³ lotniczy, kombinatoryka, sieci komputerowe, zarz¹dzanie ³añcuchem dostaw, a tak¿e ustalanie czasu reklamy w telewizji \cite{genetic_5}.



\subsection{Algorytm mrówkowy}

Obserwacje nad zachowaniami w przyrodzie wielokrotnie mia³y wp³yw na rozwój nowych rozwi¹zañ. Tak jak w przypadku algorytmu genetycznego, tak i w przypadku algorytmu mrówkowego pomys³ zosta³ zaczerpniêty z przyrody. Dok³adne dzia³anie algorytmu mrówkowego wzoruje siê na zachowaniu kolonii mrówek. Dziêki pracy zespo³owej, owady te s¹ w stanie wypracowaæ optymaln¹ œcie¿kê miêdzy siedliskiem a znalezionym pokarmem.

Dla niejednego gatunku problematyczne mog³oby byæ odtworzenie przebytej œcie¿ki. Na pocz¹tku nale¿a³oby zadaæ sobie pytanie w jaki sposób te niewielkich rozmiarów owady s¹ w stanie znacz¹co u³atwiæ sobie przetrwanie? Istotn¹ rolê odgrywa tutaj wspomniana ju¿ praca zespo³owa. To dziêki niej mrówki s¹ w stanie optymalizowaæ trasê. Innym wa¿nym czynnikiem determinuj¹cym poprawê œcie¿ki jest zapach jaki zostawiaj¹ mrówki. 

Zapach nie jest niczym innym jak feromonem wytwarzanym przez mrówki. Dziêki pozostawionemu zapachowi mrówki wiedzia³y w jaki sposób poruszali siê ich poprzednicy w zwi¹zku z czym odtworzenie trasy nie stanowi³o ju¿ powa¿nego problemu. Przy kolejnych iteracjach kolonia próbuje optymalizowaæ aktualn¹ trasê. W tym celu równie¿ wykorzystuje zapach pozostawiony w poprzednich przejœciach. Œcie¿ka jest losowo zmieniana w celu optymalizacji. Jeœli modyfikacja przynios³a oczekiwany efekt, to trasa zostaje zmieniona. 

Feromony s¹ istotnym czynnikiem w ca³ym procesie. To dziêki nim trasa jest ulepszana. Zapach posiada jedn¹ z charakterystyk która na pocz¹tku mo¿e wydawaæ siê problematyczna. Wraz z up³ywem czasu si³a zapachu s³abnie a¿ do ca³kowitego zanikniêcia. W³aœciwoœæ ta jest zaletê, a nie wadê. To dziêki pracy zespo³owej zapach na najlepszej trasie jest podtrzymywany, a na s³abszych zanika. Dziêki tej selekcji d³u¿sze trasy nie s¹ brane pod uwagê w wyniku czego zostaje trasa najkorzystniejsza.

Do wyznaczenia optymalnej trasy potrzebne s¹ d³ugoœci jakie nale¿y przebyæ do przemieszczania siê miêdzy punktami. W \ref{tabela_kosztow_ant} przedstawione s¹ przyk³adowe odleg³oœci.

\begin{table}[htb]
\centering
\caption[Krótki podpis tabeli 1 -- do spisu treœci]{Wartoœci kosztów}
\begin{tabular}{|c|c|c|c|c|}
\hline
  & A & B & C & D \\\hline
A & 0 & 3 & 8 & 2 \\\hline
B & 3 & 0 & 2 & 4 \\\hline
C & 8 & 2 & 0 & 1 \\\hline
D & 2 & 4 & 1 & 0 \\\hline
\end{tabular}
\label{tabela_kosztow_ant}
\end{table}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_init_trasa_alg.png}
	\caption{Graf z wagami}
	\label{fig:kl_init_trasa_alg}
\end{figure}

Równie wa¿ne jest wyznaczenie pocz¹tkowych wspó³czynników feromonów. Na pocz¹tku nadajmy wszystkim krawêdziom w grafie wartoœci równe 1, a wspó³czynnik parowania niech wynosi 0.5.

\begin{table}[htb]
\centering
\caption[Krótki podpis tabeli 1 -- do spisu treœci]{Wartoœci feromonów}
\begin{tabular}{|c|c|c|c|c|}
\hline
  & A & B & C & D \\\hline
A & 0 & 1 & 1 & 1 \\\hline
B & 1 & 0 & 1 & 1 \\\hline
C & 1 & 1 & 0 & 1 \\\hline
D & 1 & 1 & 1 & 0 \\\hline
\end{tabular}
\label{tabela_feromonow_ant}
\end{table}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_init_p_alg.png}
	\caption{Graf z pocz¹tkowymi wartoœciami feromonów}
	\label{fig:kl_init_trasa_alg}
\end{figure}

Posiadaj¹c pocz¹tkowe dane wyznaczmy w sposób losowy trasy dla dwóch agentów: L1 i L2. Agent L1 porusza³ siê tras¹ w której odwiedzi³ wierzcho³ki w nastêpuj¹cej kolejnoœci: A, B, C, D, A. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_l1_trasa_alg.png}
	\caption{Trasa przebyta przez agenta L1}
	\label{fig:kl_init_trasa_alg}
\end{figure}

Agent L2 wyznaczy³ nastêpuj¹c¹ trasê: A, C, B, D, A. 

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_l2_trasa_alg.png}
	\caption{Trasa przebyta przez agenta L2}
	\label{fig:kl_init_trasa_alg}
\end{figure}

Mrówki odpowiednio pokona³y dystans 8 i 16 punktów. Dziêki tej informacji mo¿na zaktualizowaæ wartoœci feromonów na poszczególnych krawêdziach. Do obliczeñ wykorzystany jest wzór: TUTAJ WZÓR DODAÆ. Krawêdzie A-B i C-D zosta³y odwiedzona jedynie przez agenta L1 w wyniku czego wartoœæ feromonu zostaje zmieniona na 10/16. Nastêpnie krawêdzie A-C i B-D zostaj¹ zaktualizowane na 9/16. Krawêdzie A-D i B-C s¹ odwiedzone dwukrotnie a wartoœæ feromonów wynosi 11/16.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{grafika/kl_p_alg.png}
	\caption{Graf z wartoœciami feromonów po modyfikacji}
	\label{fig:kl_init_trasa_alg}
\end{figure}

Ostatni¹ faz¹ algorytmu jest wyznaczenie prawdopodobieñstwa z jakim kolejni agenci bêd¹ wybieraæ kolejny wierzcho³ek. W kolejnej iteracji agent L3 znajduje siê w wierzcho³ku B. Do wyboru ma krawêdzie A, C i D. Wed³ug wzoru TUTAJ WZÓR DODAÆ wyliczane jest prawdopodobieñstwo dla wszystkich mo¿liwoœci. Przejœcie z krawêdzi B do krawêdzi A wynosi oko³o 20 PROCENT, do krawêdzi D 30 procent, a do krawêdzi C oko³o 50 PROCENT. 

Optymalna trasa zostanie wykszta³cona po wykonaniu wielu iteracji. Iloœæ iteracji nie jest zdefiniowana i dla ka¿dego przypadku mo¿e byæ ró¿na. Sytuacja wygl¹da identycznie w przypadku wyboru wartoœci p. Wa¿ne jest natomiast to, aby w trakcie dzia³ania algorytmu nie modyfikowaæ tej wartoœci. Powinno ona byæ taka sama na ka¿dym kroku algorytmu.

\subsection{Algorytmy zach³anne}
	Kolejnym spojrzeniem na poruszany w pracy problem komiwoja¿era s¹ algorytmy zach³anne (ang. greedy algorithms). Nie znajdziemy dowodu na to czy dla podanego problemu algorytm zach³anny znalaz³ poprawny wynik, jednak stosuj¹c siê do pewnych zasad mo¿emy okreœliæ, ¿e dla naszego problemu istnieje rozwi¹zanie zach³anne. G³ówn¹ strategi¹ jak¹ siê kieruj¹ jak sama nazwa wskazuje jest dokonywanie wyborów, które w danej chwili wydaj¹ siê najlepsze. Oznacza to, ¿e dokonuje siê wyborów optymalnych lokalnie w nadziei, ¿e te wybory doprowadz¹ do rozwi¹zania globalnego w rozs¹dnym czasie. W odró¿nieniu do strategii zastosowanej w programowaniu dynamicznym wybory podejmowane przez algorytmy zach³anne nie s¹ uzale¿nione od wyborów przesz³ych. Kolejnym kryterium stosowanym do ocenienia poprawnoœci rozwi¹zania zach³annego jest w³asnoœæ optymalnej pod struktury, mówi¹ca o tym, ¿e optymalne rozwi¹zanie dla ca³ego problemu istnieje jedynie przy optymalnym rozwi¹zaniu pod problemów. Dane kryterium jest równie¿ istotne w przypadku rozwi¹zywania problemów metod¹ programowania dynamicznego. Algorytmy zach³anne nie zawsze prowadz¹ jednak do optymalnych rozwi¹zañ, jednak¿e dla w wiêkszoœci problemów daj¹ wystarczaj¹ce rezultaty.
	Skorzystanie z algorytmów zach³annych czêsto okazuje siê niewystarczaj¹ce. Aby uzyskaæ lepszy efekt i polepszyæ zbudowane ju¿ trasy mo¿emy wykorzystaæ algorytmy lokalnej optymalizacji (ang. local search). U¿ycie ich na zwróconych przez algorytmy zach³anne trasach powinno zminimalizowaæ odleg³oœci miêdzy wierzcho³kami w celu poprawienia otrzymanego rozwi¹zania. Dok³adniejszy opis dzia³ania wybranych algorytmów zach³annych i metod optymalizuj¹cych zosta³ przedstawiony w podrozdzia³ach.
	

